services:
  embedding-service:
    build:
      context: .
      dockerfile: Dockerfile
    ports:
      - "8000:8000"
    volumes:
      - ./model_cache:/app/model_cache  # Persist downloaded models
    restart: always
    environment:
      - PYTHONUNBUFFERED=1  # Enables real-time logging
      - QUANTIZATION=fp32  # Options: fp32, fp16, int8 (fp16 recommended for GPU, int8 for CPU)
    deploy:
      resources:
        limits:
          memory: 4G  # Adjust based on your model's requirements
        reservations:
          memory: 2G 
